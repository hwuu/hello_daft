{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Kubernetes 部署 Ray 集群\n",
    "\n",
    "> **进阶内容**：本 Notebook 为可选的进阶指南，介绍如何在 Kubernetes 上部署 Ray 集群并连接 Daft。如果你只需要在本地使用 Ray，可以跳过本节。\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "- 了解在 Kubernetes 上部署 Ray 的意义\n",
    "- 掌握 KubeRay Operator 的安装和使用\n",
    "- 学会部署和管理 Ray 集群\n",
    "- 了解自动扩缩容配置\n",
    "- 掌握常见故障排除方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 概述\n",
    "\n",
    "### 为什么在 Kubernetes 上部署 Ray？\n",
    "\n",
    "| 场景 | 本地 Ray | K8s Ray |\n",
    "|------|---------|--------|\n",
    "| 资源规模 | 单机 CPU/内存 | 多节点弹性资源 |\n",
    "| 可用性 | 进程级 | Pod 自动重启 |\n",
    "| 扩缩容 | 手动 | 自动扩缩容 |\n",
    "| 资源隔离 | 无 | 命名空间/资源配额 |\n",
    "| 运维 | 手动管理 | 声明式管理 |\n",
    "\n",
    "### 架构概览\n",
    "\n",
    "```\n",
    "+------------------------------------------+\n",
    "|           Kubernetes Cluster             |\n",
    "|                                          |\n",
    "|  +------------------------------------+  |\n",
    "|  |       KubeRay Operator             |  |\n",
    "|  +----------------+-------------------+  |\n",
    "|                   |                      |\n",
    "|                   v                      |\n",
    "|  +------------------------------------+  |\n",
    "|  |         RayCluster CRD             |  |\n",
    "|  |                                    |  |\n",
    "|  |  +----------+  +-----------+       |  |\n",
    "|  |  | Head Pod |  | Worker Pod|       |  |\n",
    "|  |  | - GCS    |  | - Raylet  |       |  |\n",
    "|  |  | - Driver |  | - Tasks   |       |  |\n",
    "|  |  | - Dashboard| +-----------+      |  |\n",
    "|  |  +----------+  +-----------+       |  |\n",
    "|  |                 | Worker Pod|       |  |\n",
    "|  |                 | - Raylet  |       |  |\n",
    "|  |                 | - Tasks   |       |  |\n",
    "|  |                 +-----------+       |  |\n",
    "|  +------------------------------------+  |\n",
    "+------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 前置要求\n",
    "\n",
    "在开始之前，请确保已安装以下工具：\n",
    "\n",
    "| 工具 | 用途 | 安装方式 |\n",
    "|------|------|----------|\n",
    "| `kubectl` | Kubernetes 命令行工具 | [官方文档](https://kubernetes.io/docs/tasks/tools/) |\n",
    "| `helm` | Kubernetes 包管理器 | [官方文档](https://helm.sh/docs/intro/install/) |\n",
    "| `minikube` 或 `kind` | 本地 K8s 集群 | [minikube](https://minikube.sigs.k8s.io/docs/start/) / [kind](https://kind.sigs.k8s.io/) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查工具是否已安装（可选执行）\n",
    "import shutil\n",
    "\n",
    "tools = [\"kubectl\", \"helm\", \"minikube\", \"kind\"]\n",
    "for tool in tools:\n",
    "    path = shutil.which(tool)\n",
    "    status = f\"已安装 ({path})\" if path else \"未安装\"\n",
    "    print(f\"{tool}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KubeRay Operator\n",
    "\n",
    "KubeRay 是 Ray 官方的 Kubernetes Operator，负责管理 Ray 集群的生命周期。\n",
    "\n",
    "### 安装 KubeRay Operator\n",
    "\n",
    "```bash\n",
    "# 添加 KubeRay Helm 仓库\n",
    "helm repo add kuberay https://ray-project.github.io/kuberay-helm/\n",
    "helm repo update\n",
    "\n",
    "# 安装 KubeRay Operator\n",
    "helm install kuberay-operator kuberay/kuberay-operator \\\n",
    "  --version 1.3.0 \\\n",
    "  --namespace kuberay-system \\\n",
    "  --create-namespace\n",
    "\n",
    "# 验证安装\n",
    "kubectl get pods -n kuberay-system\n",
    "```\n",
    "\n",
    "预期输出：\n",
    "```\n",
    "NAME                                READY   STATUS    RESTARTS   AGE\n",
    "kuberay-operator-xxxxxxxxxx-xxxxx   1/1     Running   0          30s\n",
    "```\n",
    "\n",
    "> 也可以使用项目提供的脚本一键安装：`bash ../scripts/setup_ray_k8s.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 部署 Ray 集群\n",
    "\n",
    "### 创建命名空间\n",
    "\n",
    "```bash\n",
    "kubectl apply -f ../k8s/namespace.yaml\n",
    "```\n",
    "\n",
    "### RayCluster 配置详解\n",
    "\n",
    "项目提供了 `../k8s/ray-cluster.yaml` 配置文件，关键配置说明：\n",
    "\n",
    "```yaml\n",
    "apiVersion: ray.io/v1\n",
    "kind: RayCluster\n",
    "metadata:\n",
    "  name: ray-demo-cluster\n",
    "  namespace: ray-demo\n",
    "spec:\n",
    "  rayVersion: '2.53.0'\n",
    "  headGroupSpec:\n",
    "    rayStartParams:\n",
    "      dashboard-host: '0.0.0.0'    # 允许外部访问 Dashboard\n",
    "    template:\n",
    "      spec:\n",
    "        containers:\n",
    "        - name: ray-head\n",
    "          image: rayproject/ray:2.53.0\n",
    "          resources:\n",
    "            limits:\n",
    "              cpu: \"2\"              # Head 节点 2 CPU\n",
    "              memory: \"4Gi\"         # Head 节点 4GB 内存\n",
    "          ports:\n",
    "          - containerPort: 6379     # GCS 端口\n",
    "          - containerPort: 8265     # Dashboard 端口\n",
    "          - containerPort: 10001    # Client 端口\n",
    "  workerGroupSpecs:\n",
    "  - replicas: 2                     # 2 个 Worker\n",
    "    minReplicas: 1                  # 最少 1 个\n",
    "    maxReplicas: 4                  # 最多 4 个\n",
    "    template:\n",
    "      spec:\n",
    "        containers:\n",
    "        - name: ray-worker\n",
    "          image: rayproject/ray:2.53.0\n",
    "          resources:\n",
    "            limits:\n",
    "              cpu: \"2\"              # 每个 Worker 2 CPU\n",
    "              memory: \"4Gi\"         # 每个 Worker 4GB 内存\n",
    "```\n",
    "\n",
    "### 部署集群\n",
    "\n",
    "```bash\n",
    "kubectl apply -f ../k8s/ray-cluster.yaml\n",
    "\n",
    "# 查看集群状态\n",
    "kubectl get rayclusters -n ray-demo\n",
    "kubectl get pods -n ray-demo\n",
    "```\n",
    "\n",
    "预期输出：\n",
    "```\n",
    "NAME               STATUS   AGE\n",
    "ray-demo-cluster   Ready    60s\n",
    "\n",
    "NAME                                          READY   STATUS    RESTARTS   AGE\n",
    "ray-demo-cluster-head-xxxxx                   1/1     Running   0          60s\n",
    "ray-demo-cluster-worker-default-xxxxx-xxxxx   1/1     Running   0          55s\n",
    "ray-demo-cluster-worker-default-xxxxx-xxxxx   1/1     Running   0          55s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 连接远程 Ray 集群\n",
    "\n",
    "### 端口转发\n",
    "\n",
    "```bash\n",
    "# 转发 Ray Client 端口\n",
    "kubectl port-forward -n ray-demo svc/ray-demo-cluster-head-svc 10001:10001 &\n",
    "\n",
    "# 转发 Dashboard 端口\n",
    "kubectl port-forward -n ray-demo svc/ray-demo-cluster-head-svc 8265:8265 &\n",
    "```\n",
    "\n",
    "### 从 Daft 连接\n",
    "\n",
    "```python\n",
    "import daft\n",
    "\n",
    "# 连接远程 Ray 集群\n",
    "daft.set_runner_ray(\"ray://localhost:10001\")\n",
    "\n",
    "# 之后的操作与本地 Ray Runner 完全相同\n",
    "df = daft.read_parquet(\"s3://your-bucket/data.parquet\")\n",
    "result = df.where(df[\"price\"] > 100).collect()\n",
    "```\n",
    "\n",
    "> **注意**：连接远程集群时，数据路径需要使用集群可访问的路径（如 S3、GCS），而非本地路径。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dashboard 监控\n",
    "\n",
    "### 访问方式\n",
    "\n",
    "端口转发后，访问 http://localhost:8265 即可打开 Ray Dashboard。\n",
    "\n",
    "### 关键监控指标\n",
    "\n",
    "| 页面 | 关键指标 | 说明 |\n",
    "|------|---------|------|\n",
    "| **Cluster** | Node 状态 | 各节点 CPU/内存/GPU 使用率 |\n",
    "| **Jobs** | Job 列表 | 提交的任务状态和耗时 |\n",
    "| **Actors** | Actor 列表 | 活跃 Actor 的资源占用 |\n",
    "| **Logs** | Worker 日志 | 各节点的运行日志 |\n",
    "| **Metrics** | 系统指标 | 任务吞吐量、Object Store 使用率 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 自动扩缩容\n",
    "\n",
    "KubeRay 支持根据负载自动调整 Worker 数量。\n",
    "\n",
    "### 配置说明\n",
    "\n",
    "在 `ray-cluster.yaml` 的 `workerGroupSpecs` 中：\n",
    "\n",
    "```yaml\n",
    "workerGroupSpecs:\n",
    "- replicas: 2          # 初始 Worker 数\n",
    "  minReplicas: 1       # 最小 Worker 数（空闲时缩容到此）\n",
    "  maxReplicas: 4       # 最大 Worker 数（负载高时扩容到此）\n",
    "```\n",
    "\n",
    "### 扩缩容行为\n",
    "\n",
    "```\n",
    "Load Low          Load Medium        Load High\n",
    "+--------+        +--------+         +--------+\n",
    "| Worker |        | Worker |         | Worker |\n",
    "+--------+        +--------+         +--------+\n",
    "                  | Worker |         | Worker |\n",
    "                  +--------+         +--------+\n",
    "                                     | Worker |\n",
    "                                     +--------+\n",
    "                                     | Worker |\n",
    "                                     +--------+\n",
    "minReplicas=1     replicas=2         maxReplicas=4\n",
    "```\n",
    "\n",
    "- **扩容**：当 Ray 调度器发现资源不足时，KubeRay 自动创建新 Worker Pod\n",
    "- **缩容**：当 Worker 空闲超过一定时间后，KubeRay 自动删除多余 Worker Pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 故障排除\n",
    "\n",
    "### 常见问题\n",
    "\n",
    "| 问题 | 可能原因 | 解决方法 |\n",
    "|------|---------|----------|\n",
    "| Pod 处于 Pending 状态 | 资源不足 | `kubectl describe pod <pod>` 查看事件，增加集群资源 |\n",
    "| Pod 处于 CrashLoopBackOff | 配置错误或镜像问题 | `kubectl logs <pod>` 查看日志 |\n",
    "| 无法连接 Ray Client | 端口转发未启动 | 检查 `kubectl port-forward` 是否运行 |\n",
    "| Dashboard 无法访问 | 端口冲突或未转发 | 检查 8265 端口是否被占用 |\n",
    "| Worker 无法加入集群 | 网络策略限制 | 检查 NetworkPolicy 和 Service 配置 |\n",
    "| OOMKilled | 内存不足 | 增加 `resources.limits.memory` |\n",
    "\n",
    "### 常用调试命令\n",
    "\n",
    "```bash\n",
    "# 查看 Pod 状态\n",
    "kubectl get pods -n ray-demo -o wide\n",
    "\n",
    "# 查看 Pod 详情\n",
    "kubectl describe pod <pod-name> -n ray-demo\n",
    "\n",
    "# 查看 Pod 日志\n",
    "kubectl logs <pod-name> -n ray-demo\n",
    "\n",
    "# 进入 Pod 调试\n",
    "kubectl exec -it <pod-name> -n ray-demo -- bash\n",
    "\n",
    "# 查看 RayCluster 状态\n",
    "kubectl describe raycluster ray-demo-cluster -n ray-demo\n",
    "\n",
    "# 查看事件\n",
    "kubectl get events -n ray-demo --sort-by='.lastTimestamp'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 清理资源\n",
    "\n",
    "```bash\n",
    "# 删除 Ray 集群\n",
    "kubectl delete -f ../k8s/ray-cluster.yaml\n",
    "\n",
    "# 删除命名空间\n",
    "kubectl delete -f ../k8s/namespace.yaml\n",
    "\n",
    "# 卸载 KubeRay Operator\n",
    "helm uninstall kuberay-operator -n kuberay-system\n",
    "kubectl delete namespace kuberay-system\n",
    "```\n",
    "\n",
    "> 也可以使用项目提供的脚本一键清理：`bash ../scripts/cleanup.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "| 概念 | 说明 |\n",
    "|------|------|\n",
    "| KubeRay Operator | 管理 Ray 集群生命周期的 K8s Operator |\n",
    "| RayCluster CRD | 声明式定义 Ray 集群的配置 |\n",
    "| Head Pod | 运行 GCS、Dashboard、Driver 的主节点 |\n",
    "| Worker Pod | 执行 Tasks 和 Actors 的工作节点 |\n",
    "| 自动扩缩容 | 根据负载自动调整 Worker 数量 |\n",
    "| 端口转发 | 通过 kubectl 访问集群内部服务 |\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. **本地集群**：使用 minikube 或 kind 创建本地 K8s 集群，部署 Ray 并运行 02 中的数据处理任务。\n",
    "2. **资源调优**：修改 `ray-cluster.yaml`，调整 Worker 的 CPU 和内存配置，观察对性能的影响。\n",
    "\n",
    "---\n",
    "\n",
    "恭喜完成 Demo 2！你已经学会了：\n",
    "- Ray 的核心概念（Tasks、Actors、Object Store）\n",
    "- Daft + Ray 分布式数据处理\n",
    "- 在 Kubernetes 上部署 Ray 集群\n",
    "\n",
    "下一步：继续学习 Demo 3 —— LanceDB 向量数据库基础。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
