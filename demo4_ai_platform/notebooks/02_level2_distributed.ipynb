{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 02 - Level 2: Ray 并发任务\n",
    "\n",
    "本教程演示 Level 2 部署：引入 Ray 作为执行后端，支持并发任务。\n",
    "\n",
    "## Level 1 vs Level 2\n",
    "\n",
    "| 维度 | Level 1 | Level 2 |\n",
    "|------|---------|--------|\n",
    "| 执行后端 | LocalRunner（线程） | RayRunner（Ray Task） |\n",
    "| 并发 | 串行，一个任务跑完才能跑下一个 | 并发，多个 Ray Task 同时执行 |\n",
    "| Daft 后端 | 本地执行 | Daft on Ray（分布式执行图） |\n",
    "| 切换方式 | `PLATFORM_LEVEL=1`（默认） | `PLATFORM_LEVEL=2` |\n",
    "\n",
    "## 前置条件\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "pip install ray  # Level 2 额外依赖\n",
    "```\n",
    "\n",
    "**注意**：需要先跑过 Level 1 教程，确保 `.ai_platform/datasets/mnist_clean.lance` 已存在。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. 启动 Level 2 Server\n",
    "\n",
    "唯一的区别是设置环境变量 `PLATFORM_LEVEL=2`，Server 会自动使用 RayRunner。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import httpx\n",
    "\n",
    "# 设置 Level 2 环境变量\n",
    "env = os.environ.copy()\n",
    "env[\"PLATFORM_LEVEL\"] = \"2\"\n",
    "\n",
    "# 启动 AI Platform Server（Level 2）\n",
    "server_proc = subprocess.Popen(\n",
    "    [\"uvicorn\", \"ai_platform.app:app\", \"--port\", \"8000\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    env=env,\n",
    ")\n",
    "print(f\"Server 已启动 (PID: {server_proc.pid}, PLATFORM_LEVEL=2)\")\n",
    "\n",
    "# 等待服务就绪（Ray 初始化需要额外时间）\n",
    "time.sleep(8)\n",
    "\n",
    "BASE_URL = \"http://localhost:8000/api/v1\"\n",
    "\n",
    "# 验证服务\n",
    "resp = httpx.get(f\"{BASE_URL}/datasets\")\n",
    "print(f\"状态码: {resp.status_code}\")\n",
    "print(f\"数据集: {[d['id'] for d in resp.json()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. 并发训练：同时提交多个任务\n",
    "\n",
    "Level 1 下任务串行执行，提交第二个任务要等第一个跑完。\n",
    "\n",
    "Level 2 下任务提交为 Ray Task，可以并发执行。我们同时提交两个训练任务，用不同的超参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时提交两个训练任务，不同超参数\n",
    "configs = [\n",
    "    {\"name\": \"mnist_cnn_lr001\", \"params\": {\"epochs\": 2, \"learning_rate\": 0.001, \"batch_size\": 64, \"device\": \"cpu\"}},\n",
    "    {\"name\": \"mnist_cnn_lr01\",  \"params\": {\"epochs\": 2, \"learning_rate\": 0.01,  \"batch_size\": 64, \"device\": \"cpu\"}},\n",
    "]\n",
    "\n",
    "tasks = []\n",
    "for cfg in configs:\n",
    "    resp = httpx.post(f\"{BASE_URL}/tasks\", json={\n",
    "        \"name\": cfg[\"name\"],\n",
    "        \"input\": \".ai_platform/datasets/mnist_clean.lance\",\n",
    "        \"script\": \"mnist/mnist_cnn.py\",\n",
    "        \"params\": cfg[\"params\"],\n",
    "        \"output\": f\".ai_platform/models/{cfg['name']}.lance\",\n",
    "    })\n",
    "    task = resp.json()\n",
    "    tasks.append(task)\n",
    "    print(f\"已提交: {task['id']} ({cfg['name']})\")\n",
    "\n",
    "print(f\"\\n两个任务同时在 Ray 上执行...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轮询等待所有任务完成\n",
    "pending = {t[\"id\"]: t[\"name\"] for t in tasks}\n",
    "results = {}\n",
    "\n",
    "while pending:\n",
    "    for task_id in list(pending.keys()):\n",
    "        resp = httpx.get(f\"{BASE_URL}/tasks/{task_id}\")\n",
    "        task = resp.json()\n",
    "        if task[\"status\"] in (\"completed\", \"failed\"):\n",
    "            name = pending.pop(task_id)\n",
    "            results[name] = task\n",
    "            print(f\"{name}: {task['status']}\")\n",
    "    if pending:\n",
    "        time.sleep(5)\n",
    "\n",
    "# 对比结果\n",
    "print(\"\\n--- 超参数对比 ---\")\n",
    "for name, task in results.items():\n",
    "    if task[\"status\"] == \"completed\":\n",
    "        r = task[\"result\"]\n",
    "        print(f\"{name}: accuracy={r['accuracy']:.2%}, loss={r['test_loss']:.4f}\")\n",
    "    else:\n",
    "        print(f\"{name}: 失败 - {task.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. 可视化对比\n",
    "\n",
    "对比两组超参数的训练结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = []\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "for name, task in results.items():\n",
    "    if task[\"status\"] == \"completed\":\n",
    "        names.append(name)\n",
    "        accuracies.append(task[\"result\"][\"accuracy\"])\n",
    "        losses.append(task[\"result\"][\"test_loss\"])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.bar(names, accuracies, color=[\"steelblue\", \"coral\"])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"测试准确率\")\n",
    "ax1.set_ylim(0.9, 1.0)\n",
    "\n",
    "ax2.bar(names, losses, color=[\"steelblue\", \"coral\"])\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"测试损失\")\n",
    "\n",
    "plt.suptitle(\"Level 2: 并发超参数对比\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. 查看 Ray 集群状态\n",
    "\n",
    "Level 2 下 Ray 以本地集群模式运行，可以查看集群资源："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(address=\"auto\", ignore_reinit_error=True)\n",
    "\n",
    "resources = ray.cluster_resources()\n",
    "print(\"Ray 集群资源:\")\n",
    "for k, v in sorted(resources.items()):\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. 流式处理 + 资源分步\n",
    "\n",
    "Level 2 的另一个价值是 Daft on Ray 的流式处理，以及嵌套 Ray Task 的资源分步。\n",
    "\n",
    "Level 1 下清洗和训练是两个独立 Task，中间结果写 Lance 文件。Level 2 下可以用一个端到端脚本 `mnist_e2e.py`，通过嵌套 Ray Task 实现：\n",
    "\n",
    "```\n",
    "run()                          # 轻量协调者（1 CPU）\n",
    "  ├── clean_step.remote()      # 阶段 1: Daft 清洗（2 CPU）\n",
    "  └── train_step.remote()      # 阶段 2: PyTorch 训练（4 CPU，可加 GPU）\n",
    "```\n",
    "\n",
    "每个 step 独立声明资源，清洗完释放 CPU，训练时再申请更多。中间数据通过 Ray 对象存储传递，不写 Lance。\n",
    "\n",
    "| | 分开两个 Task | 嵌套 Ray Task (e2e) |\n",
    "|---|---|---|\n",
    "| 中间数据 | 写 Lance 文件 | Ray 对象存储，内存中流转 |\n",
    "| 资源 | 每个 Task 一套 | 每个 step 独立声明 |\n",
    "| GPU 占用 | 清洗 Task 不需要 GPU | 只有 train_step 申请 GPU |\n",
    "| 调度 | 两次 HTTP 调用 | 一次，内部 Ray 自动编排 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交端到端流式处理任务\n",
    "resp = httpx.post(f\"{BASE_URL}/tasks\", json={\n",
    "    \"name\": \"mnist_e2e\",\n",
    "    \"input\": \".ai_platform/datasets/mnist_clean.lance\",      # 读已有数据集\n",
    "    \"script\": \"mnist/mnist_e2e.py\",                          # 端到端脚本\n",
    "    \"params\": {\"epochs\": 2, \"learning_rate\": 0.001, \"batch_size\": 64, \"device\": \"cpu\"},\n",
    "    \"output\": \".ai_platform/models/mnist_e2e.lance\",\n",
    "})\n",
    "\n",
    "e2e_task = resp.json()\n",
    "print(f\"任务 ID: {e2e_task['id']}\")\n",
    "\n",
    "# 轮询等待完成\n",
    "task_id = e2e_task[\"id\"]\n",
    "while True:\n",
    "    resp = httpx.get(f\"{BASE_URL}/tasks/{task_id}\")\n",
    "    task = resp.json()\n",
    "    if task[\"status\"] in (\"completed\", \"failed\"):\n",
    "        break\n",
    "    print(f\"状态: {task['status']}...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "if task[\"status\"] == \"completed\":\n",
    "    r = task[\"result\"]\n",
    "    print(f\"\\ne2e 完成: accuracy={r['accuracy']:.2%}, loss={r['test_loss']:.4f}, mode={r['mode']}\")\n",
    "else:\n",
    "    print(f\"失败: {task.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. 清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_proc.terminate()\n",
    "server_proc.wait()\n",
    "print(\"Server 已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "Level 2 的核心变化：\n",
    "\n",
    "| 维度 | 改动 |\n",
    "|------|------|\n",
    "| 环境变量 | `PLATFORM_LEVEL=2` |\n",
    "| 执行后端 | LocalRunner → RayRunner |\n",
    "| 并发能力 | 串行 → 多个 Ray Task 并发 |\n",
    "| Daft 后端 | 本地 → `daft.context.set_runner_ray()` |\n",
    "| 流式处理 | 中间结果落盘 → 内存中流转（e2e 脚本） |\n",
    "\n",
    "**用户脚本不需要任何改动**——同样的 `mnist_cnn.py`，在 Level 1 跑线程，在 Level 2 跑 Ray Task。这就是 Runner 抽象的价值。\n",
    "\n",
    "流式处理则是 Daft on Ray 的额外收益——用户可以编写端到端脚本，让数据在 Ray 集群内存中流转，省去中间 Lance 写入。\n",
    "\n",
    "### 进阶方向\n",
    "\n",
    "- Level 3: Ray on K8s + S3 共享存储，多机多任务\n",
    "- 详见 [README.md](../ai_platform/README.md) 中的部署级别设计"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
