{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - AI Platform 教程\n",
    "\n",
    "本教程完整演示 AI Platform 的端到端流程：从数据入库、模型训练到推理服务。\n",
    "\n",
    "## 架构回顾\n",
    "\n",
    "AI Platform 是一个单服务架构：\n",
    "\n",
    "```\n",
    "用户 --> Server (8000) --> Lance 数据湖\n",
    "```\n",
    "\n",
    "Server 统一提供数据湖存储（Lance）、脚本执行（Daft）和 RESTful API。\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "- 理解 AI Platform 单服务架构\n",
    "- 通过 HTTP API 完成 MNIST 数据入库、CNN 训练、推理\n",
    "- 观察 Lance 数据湖中的数据集和模型\n",
    "- 可视化推理结果\n",
    "\n",
    "## 前置条件\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 启动服务\n",
    "\n",
    "用 `subprocess` 在后台启动 Server 的 uvicorn 进程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "import httpx\n",
    "\n",
    "# 启动 AI Platform Server\n",
    "server_proc = subprocess.Popen(\n",
    "    [\"uvicorn\", \"ai_platform.app:app\", \"--port\", \"8000\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")\n",
    "print(f\"Server 已启动 (PID: {server_proc.pid})\")\n",
    "\n",
    "# 等待服务就绪\n",
    "time.sleep(3)\n",
    "\n",
    "# 定义 API 基地址\n",
    "BASE_URL = \"http://localhost:8000/api/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证服务是否正常运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查服务是否正常运行\n",
    "resp = httpx.get(f\"{BASE_URL}/datasets\")\n",
    "print(f\"状态码: {resp.status_code}\")\n",
    "print(f\"数据集列表: {resp.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据入库（Ingestion）\n",
    "\n",
    "提交一个数据入库任务，让平台执行我们的清洗脚本 `mnist_clean.py`。\n",
    "\n",
    "脚本会：\n",
    "1. 自动下载 MNIST 数据集（60000 训练 + 10000 测试）\n",
    "2. 将 28x28 图像展平为 784 维向量\n",
    "3. 归一化像素值到 [0, 1]\n",
    "4. 写入 Lance 格式\n",
    "\n",
    "**注意**：首次运行需要下载 MNIST 数据（约 11MB），请耐心等待。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交数据入库任务\n",
    "resp = httpx.post(f\"{BASE_URL}/tasks\", json={\n",
    "    \"name\": \"mnist_ingestion\",\n",
    "    \"input\": \"download\",                                    # 自动下载 MNIST\n",
    "    \"script\": \"mnist/mnist_clean.py\",                        # 清洗脚本路径\n",
    "    \"params\": {\"normalize\": True},                           # 归一化像素值\n",
    "    \"output\": \".ai_platform/datasets/mnist_clean.lance\",     # 输出到数据湖\n",
    "})\n",
    "\n",
    "ingestion_task = resp.json()\n",
    "print(f\"任务 ID: {ingestion_task['id']}\")\n",
    "print(f\"状态: {ingestion_task['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任务在后台异步执行。我们通过轮询 `GET /tasks/{id}` 等待完成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轮询等待任务完成\n",
    "task_id = ingestion_task[\"id\"]\n",
    "while True:\n",
    "    resp = httpx.get(f\"{BASE_URL}/tasks/{task_id}\")\n",
    "    task = resp.json()\n",
    "    status = task[\"status\"]\n",
    "    if status in (\"completed\", \"failed\"):\n",
    "        break\n",
    "    print(f\"状态: {status}，等待中...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(f\"\\n最终状态: {status}\")\n",
    "if status == \"completed\":\n",
    "    print(f\"结果: {task['result']}\")\n",
    "else:\n",
    "    print(f\"错误: {task.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 查看数据集\n",
    "\n",
    "数据入库完成后，可以通过 `GET /datasets` 查看数据湖中的数据集。\n",
    "\n",
    "注意响应中的 `schema` 字段——这就是 Lance 文件的列定义：\n",
    "- `image`: 784 维浮点数组（展平后的 28x28 像素）\n",
    "- `label`: 0-9 的整数标签\n",
    "- `split`: \"train\" 或 \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出所有数据集\n",
    "resp = httpx.get(f\"{BASE_URL}/datasets\")\n",
    "datasets = resp.json()\n",
    "\n",
    "for ds in datasets:\n",
    "    print(f\"数据集: {ds['id']}\")\n",
    "    print(f\"  路径: {ds['path']}\")\n",
    "    print(f\"  行数: {ds['num_rows']}\")\n",
    "    print(f\"  Schema:\")\n",
    "    for col, dtype in ds[\"schema\"].items():\n",
    "        print(f\"    {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以查看单个数据集的详情："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 mnist_clean 数据集详情\n",
    "resp = httpx.get(f\"{BASE_URL}/datasets/mnist_clean\")\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型训练（Training）\n",
    "\n",
    "提交一个训练任务，训练一个简单的 CNN 分类器。\n",
    "\n",
    "训练脚本 `mnist_cnn.py` 会：\n",
    "1. 从 Lance 数据湖读取训练数据\n",
    "2. 构建 PyTorch DataLoader\n",
    "3. 训练 CNN（两层卷积 + 两层全连接）\n",
    "4. 评估测试集准确率\n",
    "5. 将模型权重 + 指标保存回 Lance\n",
    "\n",
    "我们用 3 个 epoch 做演示，CPU 上大约需要 1-2 分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交训练任务\n",
    "resp = httpx.post(f\"{BASE_URL}/tasks\", json={\n",
    "    \"name\": \"mnist_cnn_v1\",\n",
    "    \"input\": \".ai_platform/datasets/mnist_clean.lance\",      # 从数据湖读取\n",
    "    \"script\": \"mnist/mnist_cnn.py\",                          # 训练脚本\n",
    "    \"params\": {\n",
    "        \"epochs\": 3,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 64,\n",
    "        \"device\": \"cpu\",\n",
    "    },\n",
    "    \"output\": \".ai_platform/models/mnist_cnn_v1.lance\",      # 模型保存到数据湖\n",
    "})\n",
    "\n",
    "training_task = resp.json()\n",
    "print(f\"任务 ID: {training_task['id']}\")\n",
    "print(f\"状态: {training_task['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轮询等待训练完成\n",
    "task_id = training_task[\"id\"]\n",
    "while True:\n",
    "    resp = httpx.get(f\"{BASE_URL}/tasks/{task_id}\")\n",
    "    task = resp.json()\n",
    "    status = task[\"status\"]\n",
    "    if status in (\"completed\", \"failed\"):\n",
    "        break\n",
    "    print(f\"状态: {status}，训练中...\")\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"\\n最终状态: {status}\")\n",
    "if status == \"completed\":\n",
    "    result = task[\"result\"]\n",
    "    print(f\"准确率: {result['accuracy']:.2%}\")\n",
    "    print(f\"测试损失: {result['test_loss']:.4f}\")\n",
    "else:\n",
    "    print(f\"错误: {task.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 查看模型\n",
    "\n",
    "训练完成后，模型权重和元数据都保存在 Lance 数据湖中。\n",
    "\n",
    "Lance 表的 schema：\n",
    "- `weights`: Binary — PyTorch state_dict 的序列化字节\n",
    "- `params`: String — 超参数 JSON\n",
    "- `metrics`: String — 训练指标 JSON\n",
    "- `created_at`: String — 创建时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出所有模型\n",
    "resp = httpx.get(f\"{BASE_URL}/models\")\n",
    "models = resp.json()\n",
    "\n",
    "for m in models:\n",
    "    print(f\"模型: {m['id']}\")\n",
    "    print(f\"  路径: {m['path']}\")\n",
    "    print(f\"  Schema:\")\n",
    "    for col, dtype in m[\"schema\"].items():\n",
    "        print(f\"    {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 启动推理服务（Inference）\n",
    "\n",
    "提交一个推理任务，Server 会执行推理脚本 `mnist_serve.py`：\n",
    "1. 从 Lance 数据湖读取模型权重\n",
    "2. 用 PyTorch 加载权重到 CNN 模型\n",
    "3. 启动 FastAPI 子服务在指定端口（如 8080）\n",
    "4. 提供 `POST /predict` 端点\n",
    "\n",
    "与批处理任务不同，推理脚本会阻塞运行（uvicorn.run），保持服务直到任务被 cancel。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动推理服务\n",
    "INFERENCE_PORT = 8080\n",
    "\n",
    "resp = httpx.post(f\"{BASE_URL}/tasks\", json={\n",
    "    \"name\": \"mnist_serve\",\n",
    "    \"input\": \".ai_platform/models/mnist_cnn_v1.lance\",       # 从数据湖加载模型\n",
    "    \"script\": \"mnist/mnist_serve.py\",                        # 推理服务脚本\n",
    "    \"output\": \"\",\n",
    "    \"params\": {\"device\": \"cpu\", \"port\": INFERENCE_PORT},\n",
    "})\n",
    "\n",
    "inference_task = resp.json()\n",
    "print(f\"任务 ID: {inference_task['id']}\")\n",
    "print(f\"状态: {inference_task['status']}\")\n",
    "\n",
    "# 等待推理服务启动\n",
    "time.sleep(5)\n",
    "\n",
    "# 检查推理服务是否就绪\n",
    "try:\n",
    "    health = httpx.get(f\"http://localhost:{INFERENCE_PORT}/health\")\n",
    "    print(f\"推理服务就绪: {health.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"推理服务尚未就绪: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 调用推理\n",
    "\n",
    "推理服务就绪后，直接调用子服务的 `POST /predict` 端点发送图像数据。\n",
    "\n",
    "请求体是 784 维浮点数组（28x28 归一化像素值）。\n",
    "\n",
    "我们从数据湖中取一张真实的测试图片来试试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "\n",
    "# 从数据湖读取测试集中的前 5 张图片\n",
    "df = daft.read_lance(\".ai_platform/datasets/mnist_clean.lance\")\n",
    "pdf = df.to_pandas()\n",
    "test_samples = pdf[pdf[\"split\"] == \"test\"].head(5)\n",
    "\n",
    "print(f\"取出 {len(test_samples)} 张测试图片\")\n",
    "print(f\"真实标签: {test_samples['label'].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每张图片调用推理子服务\n",
    "predictions = []\n",
    "\n",
    "for i, row in test_samples.iterrows():\n",
    "    image_data = [float(x) for x in row[\"image\"]]  # 转为 Python float 列表\n",
    "    resp = httpx.post(\n",
    "        f\"http://localhost:{INFERENCE_PORT}/predict\",\n",
    "        json={\"image\": image_data},\n",
    "    )\n",
    "    result = resp.json()\n",
    "    predictions.append(result)\n",
    "    print(f\"真实: {row['label']}, 预测: {result['prediction']}, 置信度: {result['confidence']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化预测结果\n",
    "\n",
    "将 784 维向量还原为 28x28 图像，展示预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for idx, (ax, (_, row)) in enumerate(zip(axes, test_samples.iterrows())):\n",
    "    # 将 784 维向量还原为 28x28 图像\n",
    "    image = np.array(row[\"image\"]).reshape(28, 28)\n",
    "    ax.imshow(image, cmap=\"gray\")\n",
    "\n",
    "    pred = predictions[idx]\n",
    "    true_label = row[\"label\"]\n",
    "    pred_label = pred[\"prediction\"]\n",
    "    confidence = pred[\"confidence\"]\n",
    "\n",
    "    # 预测正确显示绿色，错误显示红色\n",
    "    color = \"green\" if pred_label == true_label else \"red\"\n",
    "    ax.set_title(f\"真实: {true_label}\\n预测: {pred_label} ({confidence:.1%})\", color=color)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"MNIST 推理结果\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率分布\n",
    "\n",
    "查看第一张图片的 10 类概率分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一张图片的概率分布\n",
    "probs = predictions[0][\"probabilities\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "bars = ax.bar(range(10), probs)\n",
    "\n",
    "# 高亮预测类别\n",
    "pred_idx = predictions[0][\"prediction\"]\n",
    "bars[pred_idx].set_color(\"green\")\n",
    "\n",
    "ax.set_xlabel(\"数字类别\")\n",
    "ax.set_ylabel(\"概率\")\n",
    "ax.set_title(f\"预测概率分布（真实标签: {test_samples.iloc[0]['label']}）\")\n",
    "ax.set_xticks(range(10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 查看所有任务\n",
    "\n",
    "回顾我们创建的所有任务："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出所有任务\n",
    "resp = httpx.get(f\"{BASE_URL}/tasks\")\n",
    "tasks = resp.json()\n",
    "\n",
    "for t in tasks:\n",
    "    print(f\"{t['id']}  status={t['status']:<10}  name={t['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 停止推理服务\n",
    "\n",
    "推理任务的脚本会阻塞运行（uvicorn.run），取消任务后 Server 会终止脚本进程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止推理服务\n",
    "resp = httpx.post(f\"{BASE_URL}/tasks/{inference_task['id']}/cancel\")\n",
    "print(f\"推理服务已停止: {resp.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 清理\n",
    "\n",
    "停止 Server 进程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止服务\n",
    "server_proc.terminate()\n",
    "server_proc.wait()\n",
    "print(\"服务已停止\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本教程完整演示了 AI Platform 的统一任务模型：\n",
    "\n",
    "| 步骤 | API | 说明 |\n",
    "|------|-----|------|\n",
    "| 数据入库 | `POST /tasks` | 下载 MNIST，归一化，写入 Lance |\n",
    "| 查看数据集 | `GET /datasets` | 查看 schema 和行数 |\n",
    "| 模型训练 | `POST /tasks` | CNN 训练，权重保存到 Lance |\n",
    "| 查看模型 | `GET /models` | 查看模型元数据 |\n",
    "| 启动推理 | `POST /tasks` | 推理脚本启动子服务 |\n",
    "| 调用推理 | `POST localhost:8080/predict` | 直接调用推理子服务 |\n",
    "| 停止推理 | `POST /tasks/{id}/cancel` | 终止推理脚本 |\n",
    "\n",
    "### 关键设计点\n",
    "\n",
    "- **统一任务 API**：所有任务共用 `/tasks` 端点，无 type 区分，平台只负责跑用户脚本\n",
    "- **Lance 作为存储层**：数据集和模型都存储在 Lance 格式中\n",
    "- **用户脚本模式**：平台不绑定特定数据集或模型，用户提供自己的清洗/训练/推理脚本\n",
    "- **推理服务由用户脚本实现**：推理脚本自行启动 FastAPI 子服务，平台不关心脚本内部做什么\n",
    "\n",
    "### 进阶方向\n",
    "\n",
    "- Level 2: 引入 Ray，支持并发任务和 Ray Serve 推理\n",
    "- Level 3: Ray on K8s + S3 共享存储，多机多任务\n",
    "- 详见 [README.md](../ai_platform/README.md) 中的部署级别设计"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
