{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 嵌入与语义搜索\n",
    "\n",
    "本 Notebook 演示如何将文本转换为向量（嵌入），并利用 LanceDB 实现语义搜索。\n",
    "\n",
    "**前置要求**：需要配置 SiliconFlow API Key（OpenAI 兼容接口）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 什么是嵌入（Embedding）？\n",
    "\n",
    "嵌入是将文本映射为高维向量的过程。语义相似的文本在向量空间中距离更近：\n",
    "\n",
    "- \"质量很好\" 和 \"品质不错\" → 向量距离**近**\n",
    "- \"质量很好\" 和 \"发货太慢\" → 向量距离**远**\n",
    "\n",
    "嵌入模型（如 Qwen3-Embedding）经过大规模文本训练，能捕捉语义信息。本教程使用 SiliconFlow 提供的 `Qwen/Qwen3-Embedding-4B` 模型（1024 维）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置 API\n",
    "\n",
    "SiliconFlow 提供 OpenAI 兼容的 API 接口。请确保已设置环境变量：\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY='your-siliconflow-key'\n",
    "export OPENAI_BASE_URL='https://api.siliconflow.cn/v1'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# 从环境变量读取配置\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "base_url = os.environ.get(\"OPENAI_BASE_URL\", \"https://api.siliconflow.cn/v1\")\n",
    "\n",
    "assert api_key, \"请设置环境变量 OPENAI_API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "EMBEDDING_MODEL = \"Qwen/Qwen3-Embedding-4B\"\n",
    "EMBEDDING_DIM = 1024\n",
    "\n",
    "print(f\"API base_url: {base_url}\")\n",
    "print(f\"Embedding model: {EMBEDDING_MODEL} ({EMBEDDING_DIM}d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 生成单条文本嵌入\n",
    "\n",
    "先用一条文本演示嵌入生成的原理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> list[float]:\n",
    "    \"\"\"调用 API 生成单条文本的嵌入向量\"\"\"\n",
    "    response = client.embeddings.create(input=[text], model=EMBEDDING_MODEL)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "# 测试\n",
    "vec = get_embedding(\"这个产品质量很好\")\n",
    "print(f\"向量维度: {len(vec)}\")\n",
    "print(f\"前 5 个分量: {vec[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证语义相似性\n",
    "\n",
    "计算几组文本之间的余弦相似度，验证嵌入是否捕捉了语义信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(a: list[float], b: list[float]) -> float:\n",
    "    \"\"\"计算两个向量的余弦相似度\"\"\"\n",
    "    a, b = np.array(a), np.array(b)\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
    "\n",
    "\n",
    "pairs = [\n",
    "    (\"质量很好\", \"品质不错\"),\n",
    "    (\"质量很好\", \"发货太慢\"),\n",
    "    (\"手机拍照清晰\", \"相机画质好\"),\n",
    "    (\"手机拍照清晰\", \"酒店环境差\"),\n",
    "]\n",
    "\n",
    "for text_a, text_b in pairs:\n",
    "    vec_a = get_embedding(text_a)\n",
    "    vec_b = get_embedding(text_b)\n",
    "    sim = cosine_similarity(vec_a, vec_b)\n",
    "    print(f\"  '{text_a}' vs '{text_b}' → 相似度: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 批量生成嵌入并写入 LanceDB\n",
    "\n",
    "加载评论数据集，批量生成嵌入向量，存入 LanceDB。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv(\"../data/reviews.csv\")\n",
    "print(f\"数据集大小: {len(reviews):,} 条\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量调用 API 生成嵌入\n",
    "\n",
    "OpenAI 兼容接口支持批量输入，每次最多传入多条文本。我们按 batch 分批处理以避免超时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batch(texts: list[str], batch_size: int = 64) -> list[list[float]]:\n",
    "    \"\"\"分批生成嵌入向量\"\"\"\n",
    "    all_embeddings: list[list[float]] = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        response = client.embeddings.create(input=batch, model=EMBEDDING_MODEL)\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "        print(f\"  已处理 {min(i + batch_size, len(texts))}/{len(texts)}\")\n",
    "    return all_embeddings\n",
    "\n",
    "\n",
    "print(\"正在生成嵌入向量...\")\n",
    "embeddings = get_embeddings_batch(reviews[\"review\"].tolist())\n",
    "print(f\"完成，共 {len(embeddings)} 个向量，维度 {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写入 LanceDB\n",
    "\n",
    "将评论数据和嵌入向量一起写入 LanceDB 表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "# 添加向量列\n",
    "reviews[\"vector\"] = embeddings\n",
    "\n",
    "# 连接数据库并创建表\n",
    "db = lancedb.connect(\"../lancedb_data\")\n",
    "table = db.create_table(\"reviews\", reviews.to_dict(\"list\"), mode=\"overwrite\")\n",
    "\n",
    "print(f\"表名: {table.name}\")\n",
    "print(f\"行数: {table.count_rows()}\")\n",
    "print(f\"Schema: {table.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 语义搜索\n",
    "\n",
    "输入一段查询文本，找到语义最相似的评论。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query: str, top_k: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"语义搜索：输入查询文本，返回最相似的评论\"\"\"\n",
    "    query_vec = get_embedding(query)\n",
    "    results = table.search(query_vec).limit(top_k).to_pandas()\n",
    "    return results\n",
    "\n",
    "\n",
    "# 搜索正面评价\n",
    "results = semantic_search(\"质量好，非常满意\")\n",
    "print(\"查询: '质量好，非常满意'\\n\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"  [{row['cat']}] (label={row['label']}) {row['review'][:60]}\")\n",
    "    print(f\"    距离: {row['_distance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜索负面评价\n",
    "results = semantic_search(\"太差了，不推荐购买\")\n",
    "print(\"查询: '太差了，不推荐购买'\\n\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"  [{row['cat']}] (label={row['label']}) {row['review'][:60]}\")\n",
    "    print(f\"    距离: {row['_distance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜索特定主题\n",
    "results = semantic_search(\"手机拍照效果\")\n",
    "print(\"查询: '手机拍照效果'\\n\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"  [{row['cat']}] (label={row['label']}) {row['review'][:60]}\")\n",
    "    print(f\"    距离: {row['_distance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 混合搜索：向量 + 过滤\n",
    "\n",
    "在语义搜索的基础上，添加标量过滤条件（如按类别、按情感标签过滤）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(\n",
    "    query: str,\n",
    "    cat: str | None = None,\n",
    "    label: int | None = None,\n",
    "    top_k: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"混合搜索：语义搜索 + 标量过滤\"\"\"\n",
    "    query_vec = get_embedding(query)\n",
    "    search = table.search(query_vec).limit(top_k)\n",
    "\n",
    "    filters: list[str] = []\n",
    "    if cat is not None:\n",
    "        filters.append(f\"cat = '{cat}'\")\n",
    "    if label is not None:\n",
    "        filters.append(f\"label = {label}\")\n",
    "    if filters:\n",
    "        search = search.where(\" AND \".join(filters))\n",
    "\n",
    "    return search.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只搜索 \"手机\" 类别的正面评论\n",
    "results = hybrid_search(\"屏幕显示效果\", cat=\"手机\", label=1)\n",
    "print(\"查询: '屏幕显示效果' (类别=手机, 正面)\\n\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"  [{row['cat']}] (label={row['label']}) {row['review'][:60]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜索 \"酒店\" 类别的负面评论\n",
    "results = hybrid_search(\"服务态度\", cat=\"酒店\", label=0)\n",
    "print(\"查询: '服务态度' (类别=酒店, 负面)\\n\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"  [{row['cat']}] (label={row['label']}) {row['review'][:60]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 创建索引优化搜索性能\n",
    "\n",
    "当数据量较大时，可以创建 IVF-PQ 索引来加速搜索。索引将向量空间划分为多个分区，搜索时只扫描最相关的分区。\n",
    "\n",
    "> 注意：当前数据集只有 3000 条，索引的加速效果不明显。数据量达到万级以上时效果更显著。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 无索引搜索\n",
    "query_vec = get_embedding(\"质量好\")\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    table.search(query_vec).limit(5).to_list()\n",
    "no_index_time = (time.time() - start) / 10\n",
    "print(f\"无索引搜索: {no_index_time*1000:.2f} ms/次\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 IVF-PQ 索引\n",
    "table.create_index(\n",
    "    metric=\"L2\",\n",
    "    num_partitions=16,\n",
    "    num_sub_vectors=32,\n",
    ")\n",
    "print(\"索引创建完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有索引搜索\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    table.search(query_vec).limit(5).to_list()\n",
    "index_time = (time.time() - start) / 10\n",
    "print(f\"有索引搜索: {index_time*1000:.2f} ms/次\")\n",
    "print(f\"加速比: {no_index_time/index_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "本 Notebook 介绍了：\n",
    "- 嵌入的概念：文本 → 高维向量，语义相似的文本向量距离近\n",
    "- 使用 OpenAI 兼容 API（SiliconFlow）生成嵌入\n",
    "- 批量生成嵌入并写入 LanceDB\n",
    "- 语义搜索：根据含义而非关键词查找相似文本\n",
    "- 混合搜索：向量搜索 + 标量过滤\n",
    "- IVF-PQ 索引：加速大规模向量搜索\n",
    "\n",
    "下一个 Notebook 将展示如何用 Daft 与 LanceDB 集成，构建完整的数据处理 + 嵌入 + 搜索 pipeline。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
