{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Daft + LanceDB 集成\n",
    "\n",
    "本 Notebook 展示 Daft 与 LanceDB 的集成使用：\n",
    "- 用 Daft 读取 Lance 格式数据（LanceDB 底层存储）\n",
    "- 用 Daft 做数据预处理\n",
    "- 用 Daft 内置的 `embed_text` 批量生成嵌入\n",
    "- 将结果写入 LanceDB\n",
    "\n",
    "**前置要求**：\n",
    "- 已运行 Notebook 02（生成了 `lancedb_data/reviews.lance`）\n",
    "- 已配置 SiliconFlow API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daft 读取 Lance 格式\n",
    "\n",
    "LanceDB 底层使用 Lance 列式存储格式。Daft 可以通过 `daft.read_lance()` 直接读取，无需经过 LanceDB API。\n",
    "\n",
    "这意味着你可以用 Daft 的 DataFrame API 对 LanceDB 中的数据做分析和处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "from daft import col\n",
    "\n",
    "# 读取 Notebook 02 写入的 reviews 表（Lance 格式）\n",
    "lance_path = \"../lancedb_data/reviews.lance\"\n",
    "df_lance = daft.read_lance(lance_path)\n",
    "\n",
    "print(f\"Schema:\")\n",
    "print(df_lance.schema())\n",
    "print(f\"\\n前 5 条:\")\n",
    "df_lance.select(\"cat\", \"label\", \"review\").limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用 Daft 分析 LanceDB 数据\n",
    "\n",
    "直接在 Lance 数据上做聚合统计，无需加载到内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按类别统计评论数和正面评论占比\n",
    "stats = (\n",
    "    df_lance\n",
    "    .groupby(\"cat\")\n",
    "    .agg(\n",
    "        col(\"review\").count().alias(\"count\"),\n",
    "        col(\"label\").mean().alias(\"positive_ratio\"),\n",
    "    )\n",
    "    .sort(\"count\", desc=True)\n",
    ")\n",
    "stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 用 Daft 做数据预处理\n",
    "\n",
    "从原始 CSV 开始，用 Daft 做清洗和过滤，为嵌入生成做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取原始 CSV\n",
    "df_raw = daft.read_csv(\"../data/reviews.csv\")\n",
    "print(f\"原始数据:\")\n",
    "df_raw.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理：过滤空评论、添加评论长度列\n",
    "df_clean = (\n",
    "    df_raw\n",
    "    .where(col(\"review\").not_null())\n",
    "    .where(col(\"review\").str.length() > 5)  # 过滤过短的评论\n",
    "    .with_column(\n",
    "        \"review_length\",\n",
    "        col(\"review\").str.length(),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"清洗后数据:\")\n",
    "df_clean.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计清洗结果\n",
    "print(\"各类别评论数:\")\n",
    "df_clean.groupby(\"cat\").agg(col(\"review\").count().alias(\"count\")).sort(\"count\", desc=True).show()\n",
    "\n",
    "print(\"\\n评论长度统计:\")\n",
    "df_clean.select(\n",
    "    col(\"review_length\").min().alias(\"min_len\"),\n",
    "    col(\"review_length\").mean().alias(\"avg_len\"),\n",
    "    col(\"review_length\").max().alias(\"max_len\"),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 用 Daft embed_text 生成嵌入\n",
    "\n",
    "Daft 内置了 `embed_text` 函数，可以直接在 DataFrame 上批量生成嵌入向量。配合 `set_provider` 设置 API 提供商。\n",
    "\n",
    "相比 Notebook 02 中手动调用 OpenAI SDK，Daft 的方式更简洁，且支持 lazy evaluation 和并行执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from daft.functions.ai import embed_text\n",
    "\n",
    "# 配置 SiliconFlow 作为 OpenAI 兼容提供商\n",
    "assert os.environ.get(\"OPENAI_API_KEY\"), \"请设置环境变量 OPENAI_API_KEY\"\n",
    "\n",
    "daft.set_provider(\n",
    "    \"openai\",\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\", \"https://api.siliconflow.cn/v1\"),\n",
    ")\n",
    "print(f\"Provider: {daft.current_provider()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为小批量数据生成嵌入（演示）\n",
    "\n",
    "先用少量数据验证 pipeline 是否正常工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"Qwen/Qwen3-Embedding-4B\"\n",
    "EMBEDDING_DIM = 1024\n",
    "\n",
    "# 取 10 条数据做演示\n",
    "df_sample = df_clean.limit(10)\n",
    "\n",
    "# 用 embed_text 生成嵌入向量\n",
    "df_with_vec = df_sample.with_column(\n",
    "    \"vector\",\n",
    "    embed_text(\n",
    "        col(\"review\"),\n",
    "        model=EMBEDDING_MODEL,\n",
    "        dimensions=EMBEDDING_DIM,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 查看结果\n",
    "df_with_vec.select(\"cat\", \"review\", \"vector\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 完整 Pipeline：Daft 预处理 → 嵌入 → 写入 LanceDB\n",
    "\n",
    "将上述步骤串联为完整的 pipeline：\n",
    "1. 读取 CSV\n",
    "2. 清洗过滤\n",
    "3. 生成嵌入\n",
    "4. 写入 LanceDB\n",
    "5. 语义搜索验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整 pipeline（使用全量数据）\n",
    "df_pipeline = (\n",
    "    daft.read_csv(\"../data/reviews.csv\")\n",
    "    .where(col(\"review\").not_null())\n",
    "    .where(col(\"review\").str.length() > 5)\n",
    "    .with_column(\n",
    "        \"vector\",\n",
    "        embed_text(\n",
    "            col(\"review\"),\n",
    "            model=EMBEDDING_MODEL,\n",
    "            dimensions=EMBEDDING_DIM,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 收集结果到 pandas（触发实际计算）\n",
    "print(\"正在执行 pipeline（读取 → 清洗 → 嵌入生成）...\")\n",
    "df_result = df_pipeline.to_pandas()\n",
    "print(f\"完成，共 {len(df_result)} 条记录，向量维度 {len(df_result['vector'].iloc[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "# 写入 LanceDB\n",
    "db = lancedb.connect(\"../lancedb_data\")\n",
    "table = db.create_table(\"reviews_daft\", df_result.to_dict(\"list\"), mode=\"overwrite\")\n",
    "\n",
    "print(f\"表名: {table.name}\")\n",
    "print(f\"行数: {table.count_rows()}\")\n",
    "print(f\"Schema: {table.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证：语义搜索\n",
    "\n",
    "在 Daft pipeline 写入的数据上执行语义搜索，验证端到端流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\", \"https://api.siliconflow.cn/v1\"),\n",
    ")\n",
    "\n",
    "\n",
    "def search_reviews(query: str, top_k: int = 5):\n",
    "    \"\"\"语义搜索评论\"\"\"\n",
    "    response = client.embeddings.create(input=[query], model=EMBEDDING_MODEL)\n",
    "    query_vec: list[float] = response.data[0].embedding\n",
    "    results = table.search(query_vec).limit(top_k).to_pandas()\n",
    "    return results\n",
    "\n",
    "\n",
    "# 测试搜索\n",
    "queries = [\"质量好，非常满意\", \"手机屏幕效果\", \"酒店服务差\"]\n",
    "for q in queries:\n",
    "    print(f\"\\n查询: '{q}'\")\n",
    "    results = search_reviews(q, top_k=3)\n",
    "    for _, row in results.iterrows():\n",
    "        print(f\"  [{row['cat']}] {row['review'][:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Daft write_lance：直接写入 Lance 格式\n",
    "\n",
    "除了通过 LanceDB API 写入，Daft 还可以直接用 `write_lance()` 写入 Lance 格式文件。\n",
    "\n",
    "这在不需要 LanceDB 索引和搜索功能、只需要高效列式存储时很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 Daft 直接写入 Lance 格式\n",
    "output_path = \"../data/reviews_processed.lance\"\n",
    "\n",
    "df_for_lance = (\n",
    "    daft.read_csv(\"../data/reviews.csv\")\n",
    "    .where(col(\"review\").not_null())\n",
    "    .where(col(\"review\").str.length() > 5)\n",
    "    .with_column(\"review_length\", col(\"review\").str.length())\n",
    ")\n",
    "\n",
    "df_for_lance.write_lance(output_path, mode=\"overwrite\")\n",
    "print(f\"已写入 Lance 格式: {output_path}\")\n",
    "\n",
    "# 验证：用 Daft 读回\n",
    "df_read_back = daft.read_lance(output_path)\n",
    "df_read_back.limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 扩展：Ray Runner 加速大规模嵌入生成\n",
    "\n",
    "当数据量达到十万甚至百万级别时，单机生成嵌入会成为瓶颈。Daft 支持 Ray 作为分布式执行引擎：\n",
    "\n",
    "```python\n",
    "# 切换到 Ray Runner（需要 Ray 集群）\n",
    "daft.context.set_runner_ray()\n",
    "\n",
    "# 同样的 pipeline 代码，自动分布式执行\n",
    "df = (\n",
    "    daft.read_csv(\"s3://bucket/reviews_large.csv\")\n",
    "    .with_column(\"vector\", embed_text(col(\"review\"), model=EMBEDDING_MODEL))\n",
    ")\n",
    "df.write_lance(\"s3://bucket/reviews.lance\")\n",
    "```\n",
    "\n",
    "Ray Runner 的优势：\n",
    "- 自动将数据分片到多个 worker 并行处理\n",
    "- 支持 S3/GCS 等云存储\n",
    "- 代码无需修改，只需切换 runner\n",
    "\n",
    "详见 [Demo 2: Ray 分布式计算](../../demo2_ray/) 了解 Ray 的使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# 清理演示生成的 Lance 文件\n",
    "shutil.rmtree(\"../data/reviews_processed.lance\", ignore_errors=True)\n",
    "print(\"清理完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "本 Notebook 展示了 Daft 与 LanceDB 的集成：\n",
    "\n",
    "- **读取 Lance 格式**：`daft.read_lance()` 直接读取 LanceDB 底层数据\n",
    "- **数据预处理**：用 Daft DataFrame API 做清洗、过滤、统计\n",
    "- **嵌入生成**：`embed_text()` 内置函数，配合 `set_provider` 使用 SiliconFlow API\n",
    "- **写入 LanceDB**：通过 `to_pandas()` 中转写入 LanceDB 表\n",
    "- **写入 Lance 格式**：`write_lance()` 直接写入 Lance 列式存储\n",
    "- **扩展**：切换 Ray Runner 即可分布式处理大规模数据\n",
    "\n",
    "这构成了一个完整的数据处理 pipeline：**数据读取 → 清洗 → 嵌入生成 → 向量存储 → 语义搜索**。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
